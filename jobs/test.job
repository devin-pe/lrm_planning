#!/bin/bash

#SBATCH --partition=gpu_a100          # Partition name
#SBATCH --gres=gpu:1                  # Number of GPUs to allocate
#SBATCH --cpus-per-task=12            # Number of CPU cores per task
#SBATCH --job-name=train_latent       # Job name (customize)
#SBATCH --ntasks=1                    # Number of tasks
#SBATCH --time=8:00:00               `# Time limit hh:mm:ss (increased for evaluation)
#SBATCH --output=/home/dpereira/lrm_planning/work/baseline_%A.out  # Standard output (%A expands to job ID)

module purge
module load 2023
module load Python/3.11.3-GCCcore-12.3.0
source /home/dpereira/lrm_planning/env/bin/activate

REPO_ROOT=/home/dpereira/lrm_planning
cd $REPO_ROOT

python test.py \
  --num_train_problems 10 \
  --num_eval_problems 10 \
  


