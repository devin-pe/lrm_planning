{
  "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
  "min_disks": 3,
  "max_disks": 5,
  "num_samples_per_prompt": 4,
  "temperature": 1.0,
  "max_new_tokens": 16384,
  "learning_rate": 1e-05,
  "batch_size": 1,
  "gradient_accumulation_steps": 8,
  "num_epochs": 3,
  "warmup_ratio": 0.1,
  "max_grad_norm": 1.0,
  "grpo_weight": 1.0,
  "constraint_weight": 0.5,
  "kl_weight": 0.01,
  "use_lora": true,
  "lora_r": 16,
  "lora_alpha": 32,
  "lora_dropout": 0.05,
  "lora_target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj"
  ],
  "max_prompt_length": 4096,
  "max_seq_length": 16384,
  "output_dir": "./training_outputs/run_20260131_142808",
  "save_steps": 9,
  "logging_steps": 1,
  "num_train_problems": 10,
  "num_eval_problems": 10
}